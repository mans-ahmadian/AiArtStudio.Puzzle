{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e572b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip freeze > requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3275402",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "218e41a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Number of GPUs: 1\n",
      "Current GPU name: NVIDIA GeForce RTX 2060\n",
      "\n",
      "GPU Properties:\n",
      "  Device 0: NVIDIA GeForce RTX 2060\n",
      "    Memory: 5.61 GB\n",
      "    Compute Capability: 7.5\n",
      "\n",
      "Default device type: torch.float32\n",
      "\n",
      "CPU tensor: tensor([1., 2., 3.])\n",
      "CUDA tensor: tensor([1., 2., 3.], device='cuda:0')\n",
      "CUDA tensor device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# If CUDA is available, print the number of GPUs\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "\n",
    "    # Print the name of the current GPU (device 0)\n",
    "    print(f\"Current GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "    # Optional: Print properties of all available GPUs\n",
    "    print(\"\\nGPU Properties:\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"  Device {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        properties = torch.cuda.get_device_properties(i)\n",
    "        print(f\"    Memory: {properties.total_memory / (1024**3):.2f} GB\")\n",
    "        print(f\"    Compute Capability: {properties.major}.{properties.minor}\")\n",
    "else:\n",
    "    print(\"PyTorch is running on CPU.\")\n",
    "\n",
    "# You can also check the default device type\n",
    "print(f\"\\nDefault device type: {torch.get_default_dtype()}\")\n",
    "\n",
    "# Try to move a tensor to the GPU\n",
    "if torch.cuda.is_available():\n",
    "    x = torch.tensor([1.0, 2.0, 3.0])\n",
    "    print(f\"\\nCPU tensor: {x}\")\n",
    "    x_cuda = x.cuda() # or x.to('cuda')\n",
    "    print(f\"CUDA tensor: {x_cuda}\")\n",
    "    print(f\"CUDA tensor device: {x_cuda.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60010505",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SD15ImageGenerator:\n",
    "    def __init__(self, model_id=\"runwayml/stable-diffusion-v1-5\", use_cuda=True, num_inference_steps=25):\n",
    "        \"\"\"\n",
    "        Initialize the Stable Diffusion 1.5 pipeline and inference settings.\n",
    "        \"\"\"\n",
    "        self.device = \"cuda\" if use_cuda and torch.cuda.is_available() else \"cpu\"\n",
    "        self.num_inference_steps = num_inference_steps\n",
    "        self.intermediate_images = []\n",
    "\n",
    "        self.pipe = StableDiffusionPipeline.from_pretrained(\n",
    "            model_id,\n",
    "            torch_dtype=torch.float16 if self.device == \"cuda\" else torch.float32,\n",
    "            safety_checker=None\n",
    "        ).to(self.device)\n",
    "\n",
    "    def _capture_step(self, step, timestep, latents):\n",
    "        \"\"\"\n",
    "        Internal callback to capture the image at each step.\n",
    "        \"\"\"\n",
    "        # Decode latent to image at this step\n",
    "        with torch.no_grad():\n",
    "            image = self.pipe.vae.decode(latents / self.pipe.vae.config.scaling_factor).sample\n",
    "            image = (image / 2 + 0.5).clamp(0, 1)\n",
    "            image = image.cpu().permute(0, 2, 3, 1).numpy()[0]\n",
    "            image_pil = Image.fromarray((image * 255).astype(\"uint8\"))\n",
    "            self.intermediate_images.append(image_pil)\n",
    "\n",
    "    def generate_image(self, prompt, negative_prompt=None, guidance_scale=7.5):\n",
    "        \"\"\"\n",
    "        Generate image and collect intermediate steps.\n",
    "        Returns a list of PIL images (one per step).\n",
    "        \"\"\"\n",
    "        self.intermediate_images = []\n",
    "\n",
    "        with torch.autocast(self.device) if self.device == \"cuda\" else torch.no_grad():\n",
    "            _ = self.pipe(\n",
    "                prompt=prompt,\n",
    "                negative_prompt=negative_prompt,\n",
    "                guidance_scale=guidance_scale,\n",
    "                num_inference_steps=self.num_inference_steps,\n",
    "                callback=self._capture_step,\n",
    "                callback_steps=1  # capture every step\n",
    "            )\n",
    "\n",
    "        return self.intermediate_images\n",
    "\n",
    "    def save_image(self, image: Image.Image, output_path: str):\n",
    "        \"\"\"\n",
    "        Save a single PIL image to the specified path.\n",
    "        \"\"\"\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        image.save(output_path)\n",
    "        print(f\"Image saved to {output_path}\")\n",
    "    def save_images(self, images, directory=\"generated\"):\n",
    "        \"\"\"\n",
    "        Save a list of images to the given directory.\n",
    "        \"\"\"\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "        for i, img in enumerate(images):\n",
    "            path = os.path.join(directory, f\"step_{i:02d}.png\")\n",
    "            img.save(path)\n",
    "        print(f\"Saved {len(images)} images to '{directory}/'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec974c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d25e775d294aeea243257db3a14b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "/media/r/Data/AI/AiArtStudio.Puzzle/.venv/lib/python3.12/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py:899: FutureWarning: `callback` is deprecated and will be removed in version 1.0.0. Passing `callback` as an input argument to `__call__` is deprecated, consider using `callback_on_step_end`\n",
      "  deprecate(\n",
      "/media/r/Data/AI/AiArtStudio.Puzzle/.venv/lib/python3.12/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py:905: FutureWarning: `callback_steps` is deprecated and will be removed in version 1.0.0. Passing `callback_steps` as an input argument to `__call__` is deprecated, consider using `callback_on_step_end`\n",
      "  deprecate(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c26dd79cdab84918a888906a9300a6c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 100 images to 'generated/'\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    generator = SD15ImageGenerator(num_inference_steps=100)\n",
    "    prompt = \"a fantasy castle floating in the sky, vivid colors, highly detailed\"\n",
    "    \n",
    "    images = generator.generate_image(prompt)\n",
    "    \n",
    "    generator.save_images(images, directory=\"generated\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
