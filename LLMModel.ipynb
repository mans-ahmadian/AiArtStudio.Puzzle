{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd556a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfcfc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConceptPromptGenerator:\n",
    "    def __init__(self, model_name=\"microsoft/Phi-4-reasoning-plus\", max_new_tokens=300, device=None):\n",
    "        self.device = device if device is not None else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True, trust_remote_code=True)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
    "            device_map=self.device,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        \n",
    "        self.model.to(self.device)\n",
    "        self.generator = pipeline(\n",
    "            \"text-generation\",\n",
    "            model=self.model,\n",
    "            tokenizer=self.tokenizer,\n",
    "\n",
    "        )\n",
    "        self.max_new_tokens = max_new_tokens\n",
    "\n",
    "    def generate(self, concept: str, category: str) -> dict:\n",
    "        few_shot = (\n",
    "            \"You are an expert in AI art prompting and factual summaries.\\n\"\n",
    "            \"Given a concept and its category, generate:\\n\"\n",
    "            \"1. A vivid prompt for Stable Diffusion 1.5\\n\"\n",
    "            \"2. A negative prompt to avoid rendering issues\\n\"\n",
    "            \"3. A short fact under 50 characters\\n\\n\"\n",
    "            \"Example:\\n\"\n",
    "            \"Concept: dog\\n\"\n",
    "            \"Category: animal\\n\"\n",
    "            \"Prompt: a happy golden retriever playing in a field, photorealistic, warm sunlight, detailed fur, 4k, realistic anatomy\\n\"\n",
    "            \"Negative Prompt: blurry, extra limbs, distorted, low quality, overexposed, unrealistic eyes\\n\"\n",
    "            \"Fact: Dogs bark to communicate\\n\\n\"\n",
    "            f\"Concept: {concept}\\n\"\n",
    "            f\"Category: {category}\\n\"\n",
    "            \"Prompt:\"\n",
    "        )\n",
    "\n",
    "        output = self.generator(\n",
    "            few_shot,\n",
    "            max_new_tokens=self.max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "        )[0][\"generated_text\"]\n",
    "\n",
    "        # Parse output from where the concept starts\n",
    "        output = output.split(f\"Concept: {concept}\")[1]\n",
    "\n",
    "        result = {\"Prompt\": \"\", \"Negative Prompt\": \"\", \"Fact\": \"\"}\n",
    "        for line in output.splitlines():\n",
    "            if line.startswith(\"Prompt:\"):\n",
    "                result[\"Prompt\"] = line[len(\"Prompt:\"):].strip()\n",
    "            elif line.startswith(\"Negative Prompt:\"):\n",
    "                result[\"Negative Prompt\"] = line[len(\"Negative Prompt:\"):].strip()\n",
    "            elif line.startswith(\"Fact:\"):\n",
    "                result[\"Fact\"] = line[len(\"Fact:\"):].strip()\n",
    "            if all(result.values()):\n",
    "                break\n",
    "        return result\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1d72d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conceptPromptGenerator=ConceptPromptGenerator(device=\"cpu\" )\n",
    "output=conceptPromptGenerator.generate(\"cat\",'animal')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c680b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def add_text_to_image(\n",
    "    image,\n",
    "    text: str,\n",
    "    org: tuple[int | None, int | None] = (10, 30),  # Bottom-left corner of the text string\n",
    "    font_face: int = cv2.FONT_HERSHEY_SIMPLEX,\n",
    "    font_scale: float = 1.0,\n",
    "    color: tuple[int, int, int] = (0, 0, 0),  # BGR color (Black by default)\n",
    "    thickness: int = 2,\n",
    "    background_color: tuple[int, int, int] = (255, 255, 255), # White background for new canvas\n",
    "    text_background_color: tuple[int, int, int] = (255, 255, 255), # White background for text by default\n",
    "    text_background_transparency: float = 0.8, # 80% transparency by default\n",
    "    padding_x: int = 5, # Horizontal padding for text background\n",
    "    padding_y: int = 5, # Vertical padding for text background\n",
    "    wordwrap: bool = False # New parameter: if True, wraps text to fit image width\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Adds text to an image, extending the image size if the text falls outside\n",
    "    the original boundaries. Supports word wrapping.\n",
    "\n",
    "    Args:\n",
    "        image: The input image. Can be an OpenCV (numpy.ndarray) or Pillow (PIL.Image.Image) image.\n",
    "        text (str): The text string to add.\n",
    "        org (tuple[int | None, int | None]): The bottom-left corner of the text string in (x, y) coordinates.\n",
    "                               Defaults to (10, 30). If x or y is None, it will be centered in that direction.\n",
    "        font_face (int): Font type. See cv2.FONT_HERSHEY_* for options.\n",
    "                         Defaults to cv2.FONT_HERSHEY_SIMPLEX.\n",
    "        font_scale (float): Font scale factor multiplied by the font-specific base size.\n",
    "                            Defaults to 1.0.\n",
    "        color (tuple[int, int, int]): Text color in BGR format. Defaults to (0, 0, 0) (Black).\n",
    "        thickness (int): Thickness of the text lines. Defaults to 2.\n",
    "        background_color (tuple[int, int, int]): Color to fill the extended canvas if the image\n",
    "                                                  needs to be resized. Defaults to (255, 255, 255) (White).\n",
    "        text_background_color (tuple[int, int, int]): Color of the text's background in BGR format.\n",
    "                                                       Defaults to (255, 255, 255) (White).\n",
    "        text_background_transparency (float): Transparency of the text background.\n",
    "                                              Value between 0.0 (fully transparent) and 1.0 (fully opaque).\n",
    "                                              Defaults to 0.8 (80% transparent).\n",
    "        padding_x (int): Horizontal padding to add around the text background. Defaults to 5 pixels.\n",
    "        padding_y (int): Vertical padding to add around the text background. Defaults to 5 pixels.\n",
    "        wordwrap (bool): If True, wraps text to fit within the image width, breaking at spaces.\n",
    "                         Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The image with the added text, in OpenCV (BGR) format.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Handle Image Input: Convert Pillow image to OpenCV format if necessary\n",
    "    if isinstance(image, Image.Image):\n",
    "        img_np = np.array(image)\n",
    "        if img_np.ndim == 2: # Grayscale image\n",
    "            img_cv = cv2.cvtColor(img_np, cv2.COLOR_GRAY2BGR)\n",
    "        elif img_np.shape[2] == 4: # RGBA image\n",
    "            img_cv = cv2.cvtColor(img_np, cv2.COLOR_RGBA2BGR)\n",
    "        else: # RGB image\n",
    "            img_cv = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)\n",
    "    elif isinstance(image, np.ndarray):\n",
    "        img_cv = image\n",
    "        # Ensure the image is BGR (3 channels) if it's grayscale\n",
    "        if img_cv.ndim == 2:\n",
    "            img_cv = cv2.cvtColor(img_cv, cv2.COLOR_GRAY2BGR)\n",
    "        elif img_cv.shape[2] == 4: # Handle RGBA if passed as numpy array\n",
    "            img_cv = cv2.cvtColor(img_cv, cv2.COLOR_RGBA2BGR)\n",
    "    else:\n",
    "        raise TypeError(\"Input image must be a PIL Image or a NumPy array (OpenCV format).\")\n",
    "\n",
    "    # Get original image dimensions\n",
    "    h_orig, w_orig = img_cv.shape[:2]\n",
    "\n",
    "    # Calculate representative text height and baseline for a single line.\n",
    "    # This is used for consistent line spacing and overall text block height calculations.\n",
    "    (text_w_dummy, text_h_single_line), baseline_single_line = cv2.getTextSize(\n",
    "        \"Tg\", font_face, font_scale, thickness\n",
    "    )\n",
    "    # A reasonable spacing between lines, often a percentage of the font height.\n",
    "    line_spacing = int(text_h_single_line * 0.5)\n",
    "\n",
    "    # --- Word Wrapping Logic ---\n",
    "    wrapped_lines_info = [] # This list will store tuples of (line_text, line_width, line_height, line_baseline) for each line.\n",
    "    max_overall_text_width = 0 # Stores the width of the widest line\n",
    "    \n",
    "    if wordwrap:\n",
    "        # Determine the maximum available width for wrapping the text within the image.\n",
    "        # This considers the initial x-position and padding.\n",
    "        if org[0] is None: # If horizontally centered, available width is image width minus double padding.\n",
    "            available_width_for_wrapping = w_orig - (2 * padding_x)\n",
    "        else: # If a specific x-coordinate is provided, available width is from that point to the right edge.\n",
    "            available_width_for_wrapping = w_orig - org[0] - padding_x\n",
    "        \n",
    "        # Ensure the available width is not negative or too small to avoid issues.\n",
    "        available_width_for_wrapping = max(10, available_width_for_wrapping)\n",
    "\n",
    "        words = text.split(' ')\n",
    "        current_line_words = []\n",
    "        current_line_text = \"\"\n",
    "\n",
    "        for word in words:\n",
    "            # Construct a test line by adding the current word (with a space if not the first word).\n",
    "            test_line_text = (current_line_text + \" \" + word).strip()\n",
    "            # Get the size of this potential line.\n",
    "            (test_w, _), _ = cv2.getTextSize(\n",
    "                test_line_text, font_face, font_scale, thickness\n",
    "            )\n",
    "\n",
    "            # If adding the word makes the line too long AND there are already words in the current line,\n",
    "            # then the current line is complete and the new word starts a new line.\n",
    "            if test_w > available_width_for_wrapping and len(current_line_words) > 0:\n",
    "                # Calculate the actual size of the completed line.\n",
    "                (line_w, line_h), line_baseline = cv2.getTextSize(\n",
    "                    current_line_text, font_face, font_scale, thickness\n",
    "                )\n",
    "                wrapped_lines_info.append((current_line_text, line_w, line_h, line_baseline))\n",
    "                max_overall_text_width = max(max_overall_text_width, line_w)\n",
    "\n",
    "                # Start a new line with the current word.\n",
    "                current_line_words = [word]\n",
    "                current_line_text = word\n",
    "            else:\n",
    "                # The word fits, so add it to the current line.\n",
    "                current_line_words.append(word)\n",
    "                current_line_text = \" \".join(current_line_words)\n",
    "        \n",
    "        # After the loop, add any remaining text in the current_line_text as the last line.\n",
    "        if current_line_text:\n",
    "            (line_w, line_h), line_baseline = cv2.getTextSize(\n",
    "                current_line_text, font_face, font_scale, thickness\n",
    "            )\n",
    "            wrapped_lines_info.append((current_line_text, line_w, line_h, line_baseline))\n",
    "            max_overall_text_width = max(max_overall_text_width, line_w)\n",
    "\n",
    "    else: # If word wrapping is not enabled, treat the entire text as a single line.\n",
    "        (text_w, text_h), baseline = cv2.getTextSize(text, font_face, font_scale, thickness)\n",
    "        wrapped_lines_info.append((text, text_w, text_h, baseline))\n",
    "        max_overall_text_width = text_w\n",
    "    \n",
    "    # Calculate the total height required by the entire block of wrapped text.\n",
    "    # This is the height from the top of the first line's ascenders to the bottom of the last line's descenders.\n",
    "    total_text_block_content_height = 0\n",
    "    if wrapped_lines_info:\n",
    "        # Top of the first line relative to its baseline (negative value)\n",
    "        first_line_top_offset_from_baseline = -(wrapped_lines_info[0][2] - wrapped_lines_info[0][3])\n",
    "        \n",
    "        # Baseline of the last line relative to the first line's baseline\n",
    "        last_line_baseline_offset_from_first_baseline = 0\n",
    "        if len(wrapped_lines_info) > 1:\n",
    "            last_line_baseline_offset_from_first_baseline = (len(wrapped_lines_info) - 1) * \\\n",
    "                                                              (text_h_single_line + line_spacing)\n",
    "        \n",
    "        # Bottom of the last line relative to its own baseline\n",
    "        last_line_bottom_offset_from_its_baseline = wrapped_lines_info[-1][3]\n",
    "\n",
    "        # Total content height = (last line's baseline + its bottom offset) - (first line's baseline + its top offset)\n",
    "        # We assume the first line's baseline is at y=0 for this calculation of the *span*.\n",
    "        total_text_block_content_height = (last_line_baseline_offset_from_first_baseline + last_line_bottom_offset_from_its_baseline) - \\\n",
    "                                          (first_line_top_offset_from_baseline)\n",
    "\n",
    "    # --- Determine Canvas Extension (Pre-calculation of text block position for extension check) ---\n",
    "    new_w, new_h = w_orig, h_orig\n",
    "    offset_x_canvas, offset_y_canvas = 0, 0\n",
    "\n",
    "    # Calculate the *desired* top-left corner of the text block's content area (without padding)\n",
    "    # relative to the original image's (0,0) if no canvas extension happens.\n",
    "    temp_text_block_x_content_start = org[0] if org[0] is not None else int((w_orig - max_overall_text_width) / 2)\n",
    "    \n",
    "    # temp_text_block_y_content_top represents the Y-coordinate of the *visual top* of the entire text block.\n",
    "    if org[1] is not None: # org[1] is the baseline of the first line\n",
    "        temp_text_block_y_content_top = org[1] + first_line_top_offset_from_baseline\n",
    "    else: # Vertical centering\n",
    "        temp_text_block_y_content_top = int((h_orig - total_text_block_content_height) / 2)\n",
    "\n",
    "    # Calculate bounding box for text block with padding for extension check\n",
    "    padded_x1 = temp_text_block_x_content_start - padding_x\n",
    "    padded_y1 = temp_text_block_y_content_top - padding_y \n",
    "    padded_x2 = temp_text_block_x_content_start + max_overall_text_width + padding_x\n",
    "    padded_y2 = temp_text_block_y_content_top + total_text_block_content_height + padding_y\n",
    "\n",
    "    # Check for left extension\n",
    "    if padded_x1 < 0:\n",
    "        offset_x_canvas = -padded_x1\n",
    "        new_w += offset_x_canvas\n",
    "\n",
    "    # Check for top extension\n",
    "    if padded_y1 < 0:\n",
    "        offset_y_canvas = -padded_y1\n",
    "        new_h += offset_y_canvas\n",
    "\n",
    "    # Recalculate padded coordinates based on potentially adjusted new_w/new_h\n",
    "    # This is needed to check for right/bottom extension against the *potential* new size.\n",
    "    # The new_w/new_h might have increased due to left/top extensions.\n",
    "    # The text block's position on this *potential* new canvas:\n",
    "    current_text_block_x_on_potential_canvas = temp_text_block_x_content_start + offset_x_canvas\n",
    "    current_text_block_y_top_on_potential_canvas = temp_text_block_y_content_top + offset_y_canvas\n",
    "\n",
    "    padded_x2_after_offset = current_text_block_x_on_potential_canvas + max_overall_text_width + padding_x\n",
    "    padded_y2_after_offset = current_text_block_y_top_on_potential_canvas + total_text_block_content_height + padding_y\n",
    "\n",
    "    # Check for right extension\n",
    "    if padded_x2_after_offset > new_w:\n",
    "        new_w = padded_x2_after_offset\n",
    "\n",
    "    # Check for bottom extension\n",
    "    if padded_y2_after_offset > new_h:\n",
    "        new_h = padded_y2_after_offset\n",
    "\n",
    "    # 4. Create new canvas if needed and paste original image.\n",
    "    if new_w > w_orig or new_h > h_orig:\n",
    "        # Create a new blank canvas with the specified background color.\n",
    "        new_image_canvas = np.full((new_h, new_w, 3), background_color, dtype=np.uint8)\n",
    "        # Paste the original image onto the new canvas at the calculated offset.\n",
    "        new_image_canvas[offset_y_canvas : offset_y_canvas + h_orig,\n",
    "                         offset_x_canvas : offset_x_canvas + w_orig] = img_cv\n",
    "        img_cv = new_image_canvas\n",
    "    \n",
    "    # Calculate the FINAL position of the text block's *content area* top-left corner on the (potentially new) canvas.\n",
    "    final_text_block_x_content_on_canvas = 0\n",
    "    final_text_block_y_content_top_on_canvas = 0\n",
    "\n",
    "    if org[0] is None: # Horizontal centering\n",
    "        # Center the entire text block (based on its widest line) horizontally on the new canvas.\n",
    "        final_text_block_x_content_on_canvas = int((img_cv.shape[1] - max_overall_text_width) / 2)\n",
    "    else: # Specific x-coordinate provided\n",
    "        final_text_block_x_content_on_canvas = temp_text_block_x_content_start + offset_x_canvas\n",
    "\n",
    "    if org[1] is None: # Vertical centering\n",
    "        # Center the entire text block vertically on the new canvas.\n",
    "        final_text_block_y_content_top_on_canvas = int((img_cv.shape[0] - total_text_block_content_height) / 2)\n",
    "    else: # Specific y-coordinate provided (baseline)\n",
    "        final_text_block_y_content_top_on_canvas = temp_text_block_y_content_top + offset_y_canvas\n",
    "\n",
    "    # 5. Place Text Background (before text) for the entire block.\n",
    "    # This is drawn only if transparency is greater than 0 and there is text to draw.\n",
    "    if text_background_transparency > 0 and wrapped_lines_info:\n",
    "        # Calculate the top-left and bottom-right corners of the entire text block's background.\n",
    "        # These are relative to the final position on the canvas.\n",
    "        x1_bg = final_text_block_x_content_on_canvas - padding_x\n",
    "        y1_bg = final_text_block_y_content_top_on_canvas - padding_y\n",
    "        x2_bg = final_text_block_x_content_on_canvas + max_overall_text_width + padding_x\n",
    "        y2_bg = final_text_block_y_content_top_on_canvas + total_text_block_content_height + padding_y\n",
    "\n",
    "        # Ensure background coordinates are within the image bounds to prevent drawing outside.\n",
    "        x1_bg = max(0, x1_bg)\n",
    "        y1_bg = max(0, y1_bg)\n",
    "        x2_bg = min(img_cv.shape[1], x2_bg)\n",
    "        y2_bg = min(img_cv.shape[0], y2_bg)\n",
    "\n",
    "        # Only draw the rectangle if the bounding box is valid (positive width and height).\n",
    "        if x2_bg > x1_bg and y2_bg > y1_bg:\n",
    "            overlay = img_cv.copy() # Create a copy to draw the background on.\n",
    "            # Draw a filled rectangle for the background.\n",
    "            cv2.rectangle(overlay, (x1_bg, y1_bg), (x2_bg, y2_bg), text_background_color, -1)\n",
    "            # Blend the overlay with the original image using the specified transparency.\n",
    "            alpha = text_background_transparency\n",
    "            cv2.addWeighted(overlay, alpha, img_cv, 1 - alpha, 0, img_cv)\n",
    "\n",
    "    # 6. Place Text (loop through each wrapped line).\n",
    "    # Calculate the baseline of the first line from the top of the text content block.\n",
    "    # The baseline of the first line is the top of the text content block + the distance from its top to its baseline.\n",
    "    current_line_y_baseline = final_text_block_y_content_top_on_canvas - first_line_top_offset_from_baseline\n",
    "\n",
    "    for i, (line_text, line_w, line_h, line_baseline) in enumerate(wrapped_lines_info):\n",
    "        line_org_x = final_text_block_x_content_on_canvas # Default to block's left edge\n",
    "        \n",
    "        # If the original request was for horizontal centering, recalculate x-origin for each line\n",
    "        # to ensure each line is individually centered within the *new* canvas.\n",
    "        if org[0] is None:\n",
    "            line_org_x = int((img_cv.shape[1] - line_w) / 2)\n",
    "\n",
    "        # Put the text on the image.\n",
    "        cv2.putText(img_cv, line_text, (line_org_x, current_line_y_baseline),\n",
    "                    font_face, font_scale, color, thickness, cv2.LINE_AA)\n",
    "        \n",
    "        # Move the y-coordinate down to the baseline of the next line.\n",
    "        # The height of the line itself is line_h, but we use text_h_single_line for consistent spacing.\n",
    "        if i < len(wrapped_lines_info) - 1: # Don't add spacing after the last line\n",
    "            current_line_y_baseline += (text_h_single_line + line_spacing)\n",
    "\n",
    "    # 7. Return the modified image.\n",
    "    return img_cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d25f675",
   "metadata": {},
   "outputs": [],
   "source": [
    "image=Image.open(\"generated/step_99.png\")\n",
    "image=add_text_to_image(\n",
    "    image,\n",
    "    text=\"This is a test of the text wrapping functionality. It should wrap correctly and not overflow the image boundaries.\",\n",
    "    org=(None, None),  # Center both horizontally and vertically\n",
    "    font_face=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "    font_scale=1.0,\n",
    "    color=(0, 0, 0),  # Black text\n",
    "    thickness=2,\n",
    "    background_color=(255, 255, 255),  # White background for the new canvas\n",
    "    text_background_color=(200, 200, 200),  # Light gray background for the text\n",
    "    text_background_transparency=0.8,  # 80% transparency for the text background\n",
    "    padding_x=20,  # Horizontal padding around the text background\n",
    "    padding_y=20,  # Vertical padding around the text background\n",
    "    wordwrap=True  # Enable word wrapping\n",
    ")\n",
    "\n",
    "# Convert the NumPy array (OpenCV format) to a Pillow Image and display it\n",
    "Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB)).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
